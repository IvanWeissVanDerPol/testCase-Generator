{
    ".env": "API_KEY=sk-DmJSIrqKMQflQNnGhKDVSoC8lbGYO1GgWVrgqkoFhWT3BlbkFJZV_XJ6-gb18LgUeMknMuoddOYUvO_mPeY1etRoMg8A\nBASE_URL=https://api.openai.com/v1/chat/completions\nLOG_FILE=suite_case_generation.log\nLOG_DIR=logs\n",
    ".vscode\\launch.json": "{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n      {\n        \"name\": \"Python: src\",\n        \"type\": \"python\",\n        \"request\": \"launch\",\n        \"program\": \"${workspaceFolder}/src/generators/generate_qa_docs.py\",\n        \"console\": \"integratedTerminal\"\n      }\n    ]\n  }\n  ",
    "config\\config.json": "{\n  \"API\": {\n    \"MODEL\": \"gpt-4\",\n    \"MAX_TOKENS\": 4000,\n    \"RETRY_COUNT\": 3,\n    \"TIMEOUT\": 30,\n    \"RATE_LIMIT_PER_MINUTE\": 60\n  },\n  \"TEMPLATES\": {\n    \"TEST_CASE_TEMPLATE\": \"templates/test_case_template.md\",\n    \"TEST_SUITE_TEMPLATE\": \"templates/test_suite_template.md\"\n  },\n  \"PROMPTS\": {\n    \"EXTRACT_TEST_CASES_FROM_SUITE\": \"extract_test_cases.md\",\n    \"DETAILED_TEST_CASE_GENERATION\": \"detailed_test_case_generation.md\",\n    \"TEST_SUITE_GENERATION\": \"test_suite_generation.md\"\n  },\n  \"PATHS\": {\n    \"CONTEXT_FOLDER\": \"src/context\",\n    \"TEST_SUITE_PATH\": \"resulting_docs/test_suites\",\n    \"TEST_CASE_PATH\": \"resulting_docs/test_cases\",\n    \"PROJECT_DATA_FOLDER\": \"resulting_docs/general_qa_docs\",\n    \"LOG_DIR\": \"logs\",\n    \"CONVERSATION_HISTORY_FILE\": \"resulting_docs/general_qa_docs/conversation_history.json\"\n  },\n  \"LOGGING\": {\n    \"LOG_FILE\": \"suite_case_generation.log\",\n    \"LOG_LEVEL\": \"DEBUG\",\n    \"LOG_DIR\": \"logs\"\n  },\n  \"GENERAL\": {\n    \"SLEEP_TIME\": 10\n  },\n  \"TEST_CASE_FIELDS\": {\n    \"TEST_CASE_ID_LABEL\": \"ID del caso de prueba\",\n    \"DESCRIPTION_LABEL\": \"DescripciÃ³n\",\n    \"PRIORITY_LABEL\": \"Prioridad\",\n    \"STATUS_LABEL\": \"Estado\"\n  }\n}\n",
    "config\\logging_config.json": "{\n  \"version\": 1,\n  \"handlers\": {\n    \"file\": {\n      \"class\": \"logging.handlers.RotatingFileHandler\",\n      \"filename\": \"logs/suite_case_generation.log\",\n      \"maxBytes\": 10485760,\n      \"backupCount\": 5,\n      \"level\": \"DEBUG\",\n      \"formatter\": \"detailed\"\n    }\n  },\n  \"formatters\": {\n    \"detailed\": {\n      \"format\": \"%(asctime)s %(name)s %(module)s %(levelname)s: %(message)s\"\n    }\n  },\n  \"loggers\": {\n    \"\": {\n      \"handlers\": [\"file\"],\n      \"level\": \"DEBUG\",\n      \"propagate\": true\n    },\n    \"api\": {\n      \"handlers\": [\"file\"],\n      \"level\": \"DEBUG\",\n      \"propagate\": false\n    },\n    \"main\": {\n      \"handlers\": [\"file\"],\n      \"level\": \"DEBUG\",\n      \"propagate\": false\n    },\n    \"utils\": {\n      \"handlers\": [\"file\"],\n      \"level\": \"DEBUG\",\n      \"propagate\": false\n    },\n    \"documentation\": {\n      \"handlers\": [\"file\"],\n      \"level\": \"DEBUG\",\n      \"propagate\": false\n    }\n  },\n  \"disable_existing_loggers\": false\n}\n",
    "debug_files\\merged_python_files.json": " ",
    "src\\api\\api_caller.py": "import json\nimport requests\nimport logging\nimport os\nfrom dotenv import load_dotenv\nfrom utils.utilsFile import load_config\n\n# Load environment variables from the .env file\nload_dotenv()\n\nclass OpenAIApiClient:\n    def __init__(self):\n        self.config = load_config()\n        self.api_key = os.getenv('API_KEY')\n        self.base_url = os.getenv('BASE_URL')\n        api_config = self.config.get('API', {})\n        self.max_tokens = api_config.get('MAX_TOKENS', 4000)\n        self.model = api_config.get('MODEL', 'gpt-4')\n        self.retry_count = api_config.get('RETRY_COUNT', 3)\n        self.timeout = api_config.get('TIMEOUT', 30)\n\n        if not self.api_key or not self.base_url:\n            raise ValueError(\"API_KEY and BASE_URL must be set in the .env file.\")\n        \n        logging.info(\"OpenAIApiClient initialized with API configurations.\")\n    def send_prompt(self, prompt: str = \"\", conversation: list = None) -> str:\n        \"\"\"Send the entire conversation history as a prompt to the OpenAI API.\"\"\"\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.api_key}\"\n        }\n\n        # Ensure conversation history is provided and in the right format\n        if not conversation:\n            conversation = [{\"role\": \"user\", \"content\": prompt}]\n        else:\n            conversation = conversation  # Send the full conversation\n        \n        data = {\n            \"model\": self.model,\n            \"messages\": conversation,\n            \"max_tokens\": self.max_tokens\n        }\n\n        try:\n            logging.info(\"Sending conversation to OpenAI API.\")\n            response = requests.post(self.base_url, headers=headers, json=data)\n\n            if response.status_code == 200:\n                logging.info(\"Received response from OpenAI API.\")\n                return response.json().get('choices', [{}])[0].get('message', {}).get('content', '')\n            else:\n                logging.error(f\"API call failed with status code {response.status_code}. Response: {response.text}\")\n                return \"\"\n        except Exception as e:\n            logging.error(f\"Error sending prompt to OpenAI API: {e}\")\n            return \"\"\n\n\n",
    "src\\context\\context_manager.py": "import os\nimport json\nimport logging\nfrom api.api_caller import OpenAIApiClient\nfrom utils.utilsFile import load_config, load_context_files\n\nconfig = load_config()\nCONVERSATION_HISTORY_FILE = config['PATHS'].get('CONVERSATION_HISTORY_FILE', 'conversation_history.json')\n\n\ndef load_conversation_history() -> list:\n    \"\"\"Load the conversation history from a JSON file.\"\"\"\n    try:\n        if os.path.exists(CONVERSATION_HISTORY_FILE):\n            with open(CONVERSATION_HISTORY_FILE, \"r\", encoding=\"utf-8\") as file:\n                conversation = json.load(file)\n                logging.info(\"Successfully loaded conversation history.\")\n                return conversation\n        else:\n            logging.warning(f\"Conversation history file not found: {CONVERSATION_HISTORY_FILE}\")\n            return []\n    except Exception as e:\n        logging.error(f\"Error loading conversation history: {e}\")\n        return []\n\n\ndef save_conversation_history(conversation: list) -> None:\n    \"\"\"Save the conversation history to a JSON file.\"\"\"\n    try:\n        with open(CONVERSATION_HISTORY_FILE, \"w\", encoding=\"utf-8\") as file:\n            json.dump(conversation, file, ensure_ascii=False, indent=4)\n            logging.info(\"Successfully saved conversation history.\")\n    except Exception as e:\n        logging.error(f\"Error saving conversation history: {e}\")\n\n\ndef start_new_conversation() -> None:\n    \"\"\"Start a new conversation with the context from general_qa_docs.\"\"\"\n    # Load the context from the general_qa_docs folder\n    context = load_context_files(config['PATHS']['PROJECT_DATA_FOLDER'])\n    \n    # Start the conversation with this context\n    conversation = [{'role': 'system', 'content': context}]\n    save_conversation_history(conversation)\n    logging.info(\"New conversation started with general QA docs context.\")\n\n\n\ndef continue_conversation(new_prompt: str) -> str:\n    \"\"\"Continue an existing conversation with a new prompt.\"\"\"\n    conversation = load_conversation_history()\n\n    # Append the user's new prompt to the conversation\n    conversation.append({'role': 'user', 'content': new_prompt})\n\n    # Send the entire conversation to the API\n    client = OpenAIApiClient()\n    response = client.send_prompt(\"\", conversation)  # Pass the conversation without an initial prompt\n\n    if response:\n        # Append the AI response to the conversation\n        conversation.append({'role': 'assistant', 'content': response})\n        save_conversation_history(conversation)\n        return response\n    else:\n        logging.error(\"Failed to get response from OpenAI.\")\n        return \"\"\n",
    "src\\documentation\\document_generator.py": "import logging\nimport os\nfrom api.api_caller import OpenAIApiClient\nfrom utils.utilsFile import load_template, save_content_to_file, load_config\nfrom utils.prompt_renderer import render_prompt\nfrom utils.directory_utils import ensure_directory_exists\n\n# Load the configuration from the JSON file\nconfig = load_config()\n\n# Load templates and configuration values from the JSON file\nTEMPLATE_TEST_CASE = load_template(config['TEMPLATES']['TEST_CASE_TEMPLATE'])\nTEMPLATE_TEST_SUITE = load_template(config['TEMPLATES']['TEST_SUITE_TEMPLATE'])\nPROMPT_DETAILED_TEST_CASE = config['PROMPTS']['DETAILED_TEST_CASE_GENERATION']\nPROMPT_TEST_SUITE_GENERATION = config['PROMPTS']['TEST_SUITE_GENERATION']\nTEST_SUITE_PATH = config['PATHS']['TEST_SUITE_PATH']\nTEST_CASE_PATH = config['PATHS']['TEST_CASE_PATH']\n\ndef create_test_suite(prompt: str) -> str:\n    client = OpenAIApiClient()\n    variables = {\n        'template': TEMPLATE_TEST_SUITE,\n        'description': prompt\n    }\n    full_prompt = render_prompt(PROMPT_TEST_SUITE_GENERATION, variables)\n\n    logging.info(f\"Creating test suite with prompt: {prompt}\")\n\n    try:\n        response = client.send_prompt(full_prompt)\n        if response:\n            file_path = os.path.join(TEST_SUITE_PATH, 'generated_test_suite.txt')\n            ensure_directory_exists(os.path.dirname(file_path))\n            save_content_to_file(file_path, response)\n            logging.info(f\"Test suite saved to {file_path}\")\n            return file_path\n        else:\n            logging.error(\"Failed to generate test suite.\")\n            return \"\"\n    except Exception as e:\n        logging.error(f\"Error generating test suite: {e}\")\n        return \"\"\n\ndef create_test_cases(suite_id: str, suite_description: str, test_cases: list) -> None:\n    \"\"\"\n    Generates detailed test cases based on the provided suite ID, description, and list of test cases.\n    Each test case is saved as a separate file named after its Test Case ID.\n\n    Parameters:\n        suite_id (str): The unique ID of the test suite.\n        suite_description (str): The description of the test suite.\n        test_cases (list): A list of dictionaries containing the test case details.\n    \"\"\"\n    client = OpenAIApiClient()\n    for test_case in test_cases:\n        # Extract necessary variables from the test_case dictionary\n        test_case_id = test_case.get('Test Case ID')\n        description = test_case.get('Description')\n        priority = test_case.get('Priority')\n\n        if not all([test_case_id, description, priority]):\n            logging.error(f\"Missing required fields in test case: {test_case}\")\n            continue  # Skip this test case if essential fields are missing\n\n        # Derive additional fields required by the template\n        test_case_name = test_case.get('Nombre del Caso de Prueba') or description[:50]\n\n        # Construct the variables dictionary required by the prompt template\n        variables = {\n            'test_case_id': test_case_id,\n            'test_case_name': test_case_name,\n            'description': description,\n            'template_test_case': TEMPLATE_TEST_CASE,\n        }\n\n        # Render the prompt using the updated template and variables\n        full_prompt = render_prompt(PROMPT_DETAILED_TEST_CASE, variables)\n        logging.info(f\"Creating test case for ID: {test_case_id}\")\n        print(f\"Creating test case for ID: {test_case_id}\")\n\n        try:\n            response = client.send_prompt(full_prompt)\n            if response:\n                # Save the test case to a file\n                file_path = os.path.join(TEST_CASE_PATH, suite_id, f\"{test_case_id}.md\")\n                ensure_directory_exists(os.path.dirname(file_path))\n                save_content_to_file(file_path, response)\n                logging.info(f\"Test case {test_case_id} saved to {file_path}\")\n                print(f\"Test case {test_case_id} saved to {file_path}\")\n            else:\n                logging.error(f\"Failed to generate test case {test_case_id}\")\n                print(f\"Failed to generate test case {test_case_id}\")\n        except Exception as e:\n            logging.error(f\"Error generating test case {test_case_id}: {e}\")\n            print(f\"Error generating test case {test_case_id}: {e}\")\n",
    "src\\generators\\generate_suites_cases.py": "import json\nimport os\nimport logging\nimport re\nimport sys\n\n# Set up project root\nproject_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.append(project_root)\n\nfrom utils.directory_utils import ensure_directory_exists\nfrom utils.prompt_renderer import render_prompt\nfrom api.api_caller import OpenAIApiClient\nfrom documentation.document_generator import create_test_suite, create_test_cases\nfrom utils.utilsFile import load_config, load_context_files  # Use load_context_files to get the context\n\n# Load configuration\nconfig = load_config(\"config/config.json\")\n\nlogging.basicConfig(\n    filename=config['LOGGING']['LOG_FILE'],\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s'\n)\n\ndef extract_test_cases_from_suite(suite_description: str) -> list:\n    client = OpenAIApiClient()\n    variables = {\n        'suite_description': suite_description\n    }\n    full_prompt = render_prompt('extract_test_cases.md', variables)\n\n    logging.info(\"Extracting test cases from suite description using OpenAI.\")\n\n    try:\n        response = client.send_prompt(full_prompt)\n        cleaned_response = re.sub(r'```json|```', '', response).strip()\n        test_cases = json.loads(cleaned_response)\n        logging.info(f\"Extracted test cases: {test_cases}\")\n        return test_cases\n    except Exception as e:\n        logging.error(f\"Error extracting test cases: {e}\")\n        return []\n\ndef generate_test_cases_from_suite(suite_path: str = None):\n    if suite_path:\n        if os.path.exists(suite_path):\n            logging.info(f\"Generating test cases based on suite file at {suite_path}\")\n            with open(suite_path, \"r\", encoding=\"utf-8\") as suite_file:\n                suite_description = suite_file.read()\n\n            suite_id = os.path.basename(suite_path).split(\".\")[0]\n            test_cases = extract_test_cases_from_suite(suite_description)\n\n            # Load context from the general_qa_docs folder\n            context = load_context_files(config['PATHS']['PROJECT_DATA_FOLDER'])\n            logging.info(f\"Context loaded from general_qa_docs: {context[:200]}...\")  # Log first 200 chars for validation\n\n            # Ensure the test case directory exists\n            output_dir = f\"{config['PATHS']['TEST_CASE_PATH']}/{suite_id}\"\n            ensure_directory_exists(output_dir)\n            create_test_cases(suite_id, suite_description, test_cases)\n        else:\n            logging.error(f\"Test suite file not found at {suite_path}\")\n    else:\n        logging.warning(\"No suite path provided.\")\n\nif __name__ == \"__main__\":\n    generate_test_cases_from_suite(suite_path=\"resulting_docs/test_suites/Functional_Test_Suite/Functional Test Suite - Mobile App.md\")\n",
    "src\\utils\\directory_utils.py": "import os\n\ndef ensure_directory_exists(path):\n    \"\"\"Ensure that the given directory path exists.\"\"\"\n    if not os.path.exists(path):\n        os.makedirs(path)\n",
    "src\\utils\\logging_setup.py": "import logging.config\nimport json\nimport os\n\ndef setup_logging(default_path='config/logging_config.json', default_level=logging.INFO):\n    \"\"\"Set up logging configuration from a file or use defaults.\"\"\"\n    if os.path.exists(default_path):\n        with open(default_path, 'r') as f:\n            config = json.load(f)\n        logging.config.dictConfig(config)\n    else:\n        logging.basicConfig(level=default_level)\n",
    "src\\utils\\prompt_renderer.py": "from jinja2 import Environment, FileSystemLoader\nimport os\nimport logging\n\ndef render_prompt(template_name: str, variables: dict) -> str:\n    \"\"\"Renders a prompt template with the given variables.\"\"\"\n    templates_dir = os.path.join(os.path.dirname(__file__), '..', '..', 'config', 'prompts')\n    templates_dir = os.path.abspath(templates_dir)  # Convert to absolute path\n\n    logging.debug(f\"Templates directory: {templates_dir}\")\n\n    env = Environment(loader=FileSystemLoader(templates_dir), autoescape=False)\n    try:\n        template = env.get_template(template_name)\n        return template.render(variables)\n    except Exception as e:\n        logging.error(f\"Error rendering template {template_name}: {e}\")\n        raise\n",
    "src\\utils\\retry_utils.py": "import time\nimport logging\n\ndef retry_with_backoff(func, max_retries=3, backoff_factor=2):\n    \"\"\"Retries a function with exponential backoff on failure.\"\"\"\n    for attempt in range(max_retries):\n        try:\n            return func()\n        except Exception as e:\n            logging.error(f\"Attempt {attempt+1} failed: {e}\")\n            if attempt < max_retries - 1:\n                time.sleep(backoff_factor ** attempt)\n            else:\n                raise e\n",
    "src\\utils\\utilsFile.py": "import json\nimport logging\nimport os\n\ndef load_config(config_path=\"config/config.json\") -> dict:\n    \"\"\"\n    Loads the configuration from the specified config.json file.\n\n    Parameters:\n        config_path (str): Path to the config.json file.\n\n    Returns:\n        dict: The loaded configuration as a dictionary.\n    \"\"\"\n    try:\n        logging.info(f\"Loading configuration from: {config_path}\")\n        with open(config_path, \"r\", encoding=\"utf-8\") as config_file:\n            config = json.load(config_file)\n            logging.info(f\"Configuration loaded successfully from {config_path}\")\n            return config\n    except FileNotFoundError:\n        logging.error(f\"Configuration file not found: {config_path}\")\n        return {}\n    except json.JSONDecodeError as e:\n        logging.error(f\"Error decoding config file: {e}\")\n        return {}\n\ndef save_content_to_file(file_path: str, content: str) -> None:\n    \"\"\"\n    Saves the provided content to the specified file path.\n\n    Parameters:\n        file_path (str): The path to the file.\n        content (str): The content to be saved.\n    \"\"\"\n    try:\n        logging.info(f\"Saving content to file: {file_path}\")\n        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n            file.write(content)\n            logging.info(f\"Successfully saved content to {file_path}\")\n    except Exception as e:\n        logging.error(f\"Error saving file {file_path}: {e}\")\n\ndef load_template(template_path: str) -> str:\n    \"\"\"\n    Loads the template from the specified path.\n\n    Parameters:\n        template_path (str): The path to the template file.\n\n    Returns:\n        str: The content of the template file.\n    \"\"\"\n    try:\n        logging.info(f\"Loading template from: {template_path}\")\n        with open(template_path, \"r\", encoding=\"utf-8\") as template_file:\n            template = template_file.read()\n            logging.info(f\"Successfully loaded template from {template_path}\")\n            return template\n    except FileNotFoundError:\n        logging.error(f\"Template file not found: {template_path}\")\n        return \"\"\n    except Exception as e:\n        logging.error(f\"Error loading template file: {e}\")\n        return \"\"\n\ndef load_context_files(context_folder: str) -> str:\n    \"\"\"\n    Loads all files from the specified context folder and concatenates their content into a single string.\n    \"\"\"\n    context_content = \"\"\n    for root, _, files in os.walk(context_folder):\n        for file in files:\n            file_path = os.path.join(root, file)\n            try:\n                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                    context_content += f\"\\n\\n---\\n\\n{f.read()}\"\n                    logging.info(f\"Loaded context file: {file_path}\")\n            except Exception as e:\n                logging.error(f\"Error loading file {file_path}: {e}\")\n    return context_content\n"
}